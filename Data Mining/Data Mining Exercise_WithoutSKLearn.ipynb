{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uABSQBqs7T-I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/reviews_sentimental_analysis.csv', delimiter=',')\n",
        "\n",
        "# Replace null or NaN values with empty string\n",
        "df['r_cons'] = df['r_cons'].fillna('')\n",
        "df['r_pros'] = df['r_pros'].fillna('')\n",
        "\n",
        "# Create a dictionary to map company names to numeric IDs\n",
        "companies = sorted(list(set(df['header_employer_name'].values)))\n",
        "company_to_id = {company: i for i, company in enumerate(companies)}\n",
        "id_to_company = {i: company for company, i in company_to_id.items()}\n",
        "df['company_id'] = df['header_employer_name'].apply(lambda x: company_to_id[x])\n",
        "\n",
        "# Define a function to tokenize a text string into words\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Define a function to compute the TF-IDF matrix\n",
        "def tfidf_matrix(texts):\n",
        "    # Compute the document frequency of each word\n",
        "    word_df = {}\n",
        "    for text in texts:\n",
        "        for word in set(tokenize(text)):\n",
        "            word_df[word] = word_df.get(word, 0) + 1\n",
        "    # Compute the inverse document frequency of each word\n",
        "    num_docs = len(texts)\n",
        "    word_idf = {}\n",
        "    for word, df in word_df.items():\n",
        "        word_idf[word] = np.log(num_docs / df)\n",
        "    # Compute the term frequency-inverse document frequency matrix\n",
        "    tfidf_matrix = np.zeros((len(texts), len(word_idf)))\n",
        "    for i, text in enumerate(texts):\n",
        "        tf = {}\n",
        "        for word in tokenize(text):\n",
        "            tf[word] = tf.get(word, 0) + 1\n",
        "        for j, word in enumerate(word_idf.keys()):\n",
        "            if word in tf:\n",
        "                tfidf_matrix[i, j] = tf[word] * word_idf[word]\n",
        "    return tfidf_matrix\n",
        "\n",
        "\n",
        "# Compute the TF-IDF matrix for the pros and cons\n",
        "X = tfidf_matrix(df['r_cons'] + ' ' + df['r_pros'])\n",
        "\n",
        "# Train a linear regression model to predict the company rating based on the TF-IDF matrix\n",
        "X_train = X[:5000, :]\n",
        "y_train = df['r_company_rating'][:5000]\n",
        "try:\n",
        "    w = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
        "except np.linalg.LinAlgError:\n",
        "    w = np.linalg.pinv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
        "\n",
        "# Predict the overall employer score based on the pros and cons\n",
        "df['overall_score'] = X.dot(w)\n",
        "\n",
        "# Group the data by employer ID and calculate the mean overall score for each employer\n",
        "df_mean = df.groupby(['company_id'])['overall_score'].mean().reset_index()\n",
        "\n",
        "# Create a bar plot with employer names on the x-axis and predicted overall employer scores on the y-axis\n",
        "plt.bar([id_to_company[i] for i in df_mean['company_id']], df_mean['overall_score'])\n",
        "plt.xlabel('Employer Name')\n",
        "plt.ylabel('Predicted Overall Employer Score')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of employer names to test\n",
        "employer_names = ['Atlassian', 'Google', 'Intel', 'Siemplify', 'Forter']\n",
        "\n",
        "# Filter the dataframe to only include the selected employer names\n",
        "df_filtered = df[df['header_employer_name'].isin(employer_names)]\n",
        "\n",
        "# Group the filtered data by employer name and calculate the mean overall score for each employer\n",
        "df_mean = df_filtered.groupby(['header_employer_name'])['overall_score'].mean().reset_index()\n",
        "\n",
        "# Create a bar plot with employer names on the x-axis and predicted overall employer scores on the y-axis\n",
        "plt.bar(df_mean['header_employer_name'], df_mean['overall_score'])\n",
        "plt.xlabel('Employer Name')\n",
        "plt.ylabel('Predicted Overall Employer Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0do-NHFIPaen"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}